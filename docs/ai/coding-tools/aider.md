# Aider

AI pair programming in your terminal with native local model support.

## Overview

Aider provides:

- **Git-aware** - Understands your repository structure
- **Auto-commits** - Commits changes with meaningful messages
- **Local models** - Native Ollama and OpenAI-compatible support
- **Multi-file** - Edit multiple files in one session
- **Conversation** - Iterative development with context

## Installation

### pip

```bash
pip install aider-chat

# Or with uv
uv pip install aider-chat
```

### pipx (Recommended)

```bash
pipx install aider-chat
```

### Verify

```bash
aider --version
```

## Basic Usage

### Start Session

```bash
# In a git repository
cd /path/to/project
aider

# With specific files
aider src/main.py tests/test_main.py

# With all Python files
aider *.py
```

### Chat Commands

| Command | Action |
|---------|--------|
| `/add <file>` | Add file to context |
| `/drop <file>` | Remove file from context |
| `/ls` | List files in context |
| `/diff` | Show uncommitted changes |
| `/undo` | Undo last change |
| `/commit` | Commit without changes |
| `/run <cmd>` | Run shell command |
| `/help` | Show all commands |

## Local Model Configuration

### Using Ollama

```bash
# Start Ollama
ollama serve

# Pull a coding model
ollama pull deepseek-coder-v2:16b

# Run Aider with Ollama
aider --model ollama/deepseek-coder-v2:16b
```

### With Model Alias

Create `~/.aider.conf.yml`:

```yaml
model: ollama/deepseek-coder-v2:16b
```

Then just run:

```bash
aider
```

### OpenAI-Compatible API

```bash
# Set environment
export OPENAI_API_BASE=http://localhost:8080/v1
export OPENAI_API_KEY=not-needed

# Run with model name
aider --model openai/llama3.3
```

### Multiple Models

Use different models for different purposes:

```bash
# Main model for editing
aider --model ollama/deepseek-coder-v2:16b \
      --weak-model ollama/llama3.2:8b
```

## Recommended Models

| Use Case | Model | Command |
|----------|-------|---------|
| General coding | DeepSeek Coder V2 16B | `--model ollama/deepseek-coder-v2:16b` |
| Complex refactoring | Llama 3.3 70B | `--model ollama/llama3.3:70b` |
| Quick fixes | Mistral 7B | `--model ollama/mistral:7b` |
| Large context | Qwen 2.5 32B | `--model ollama/qwen2.5:32b` |

## Configuration

### Configuration File

Create `~/.aider.conf.yml`:

```yaml
# Model settings
model: ollama/deepseek-coder-v2:16b
weak-model: ollama/mistral:7b

# Git settings
auto-commits: true
auto-commit-message: true
dirty-commits: false

# Display settings
dark-mode: true
stream: true

# Context settings
map-tokens: 1024
map-refresh: auto
```

### Per-Project Config

Create `.aider.conf.yml` in project root:

```yaml
model: ollama/qwen2.5-coder:32b
auto-commits: false

# Project-specific ignores
aiderignore:
  - "*.log"
  - "node_modules"
  - ".env"
```

### Environment Variables

```bash
# Model configuration
export AIDER_MODEL=ollama/deepseek-coder-v2:16b
export AIDER_WEAK_MODEL=ollama/mistral:7b

# API configuration
export OLLAMA_HOST=http://localhost:11434

# Or for OpenAI-compatible
export OPENAI_API_BASE=http://localhost:8080/v1
export OPENAI_API_KEY=not-needed
```

## Git Integration

### Auto-Commits

Aider commits changes automatically:

```
# Example commit message generated by Aider
feat: Add input validation to user registration

- Added email format validation
- Added password strength requirements
- Updated error messages
```

### Disable Auto-Commits

```bash
# Disable for session
aider --no-auto-commits

# Or in config
auto-commits: false
```

### Undo Changes

```bash
# In Aider session
/undo

# Reverts last AI change and git commit
```

## Advanced Usage

### Add Files Dynamically

```bash
# During session
/add src/utils.py
/add tests/test_utils.py

# Read-only (for context)
/read-only docs/API.md
```

### Run Tests

```bash
# Run tests after changes
/run pytest tests/

# If tests fail, Aider will help fix
```

### Repository Map

Aider creates a map of your codebase:

```bash
# Show repository map
/map

# Refresh map
/map-refresh
```

## Working with Large Codebases

### Context Management

```bash
# Limit context window
aider --map-tokens 2048

# Exclude patterns
aider --aiderignore ".aiderignore"
```

### .aiderignore

Create `.aiderignore`:

```
# Ignore patterns
node_modules/
.git/
*.log
*.pyc
__pycache__/
dist/
build/
.env
```

## Multi-Model Setup

### Architect Mode

Use a stronger model for planning:

```bash
aider --model ollama/llama3.3:70b \
      --editor-model ollama/deepseek-coder-v2:16b
```

### Weak Model

Faster model for simple operations:

```bash
aider --model ollama/deepseek-coder-v2:16b \
      --weak-model ollama/mistral:7b
```

## Docker Usage

### Run in Container

```bash
docker run -it --rm \
  -v $(pwd):/app \
  -e OLLAMA_HOST=http://host.docker.internal:11434 \
  paulgauthier/aider \
  --model ollama/deepseek-coder-v2:16b
```

### With docker-compose

```yaml
services:
  aider:
    image: paulgauthier/aider
    volumes:
      - .:/app
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - AIDER_MODEL=ollama/deepseek-coder-v2:16b
    depends_on:
      - ollama
    tty: true
    stdin_open: true
```

## Troubleshooting

### Model Not Found

```bash
# Verify Ollama has model
ollama list

# Pull if missing
ollama pull deepseek-coder-v2:16b

# Check model name
aider --model ollama/deepseek-coder-v2:16b
```

### Slow Responses

- Use smaller model for quick tasks
- Reduce `--map-tokens`
- Use `--no-stream` for faster display

### Git Issues

```bash
# Ensure in git repo
git status

# Initialize if needed
git init
git add .
git commit -m "Initial commit"

# Then run Aider
aider
```

### Context Too Large

```bash
# Add fewer files
aider src/main.py  # Instead of aider *.py

# Increase context limit (if model supports)
aider --model ollama/qwen2.5:32b  # 128K context
```

## Comparison with Alternatives

| Feature | Aider | Claude Code | Cline |
|---------|-------|-------------|-------|
| Interface | CLI | CLI | VS Code |
| Local models | Native | Via proxy | Native |
| Git integration | Excellent | Good | Limited |
| Auto-commits | Yes | Optional | No |
| Multi-file | Yes | Yes | Yes |

## See Also

- [AI Coding Tools Index](index.md) - Tool comparison
- [Ollama](../inference-engines/ollama.md) - Local model serving
- [Choosing Models](../models/choosing-models.md) - Model selection
- [Claude Code](claude-code.md) - Alternative CLI tool
